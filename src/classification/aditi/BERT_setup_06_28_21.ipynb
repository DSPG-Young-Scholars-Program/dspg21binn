{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"Data_600_Labeled_Final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>an</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>body</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Does it mention an innovation (yes,no,unsure)?</th>\n",
       "      <th>What is the company?</th>\n",
       "      <th>Where is company mentioned (title,body,snippet,all)?</th>\n",
       "      <th>What is the product name?</th>\n",
       "      <th>Where is the product name mentioned(title,body,snippet,all)</th>\n",
       "      <th>What could indicate that this is a product (for use in our algorithms, e.g. TM,R,C,CAPITAL LETTERS, Quotes,Used with certain key phrases or words etc.)?</th>\n",
       "      <th>Features of the product, if mentioned</th>\n",
       "      <th>assignee</th>\n",
       "      <th>YN_INNOVATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>WATERTWN20141208eac30001o</td>\n",
       "      <td>A REVIEW OF FOUR APPS THAT WILL HELP YOU SHOP ...</td>\n",
       "      <td>Want to save some cash while holiday shopping?...</td>\n",
       "      <td>I found four apps to recommend after testing m...</td>\n",
       "      <td>A REVIEW OF FOUR APPS THAT WILL HELP YOU SHOP ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aditi</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>596</td>\n",
       "      <td>TELWK00020130531e96500010</td>\n",
       "      <td>Transaction Network Services; TNS Unveils Uniq...</td>\n",
       "      <td>2013 JUN 5 (VerticalNews) -- By a News Reporte...</td>\n",
       "      <td>TNS has partnered with leading mobile and land...</td>\n",
       "      <td>Transaction Network Services; TNS Unveils Uniq...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aditi</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>597</td>\n",
       "      <td>INTA000020140410ea4a00009</td>\n",
       "      <td>Red Hat introduces new OpenStack training course</td>\n",
       "      <td>Red Hat, Inc. (NYSE: RHT) said it has announce...</td>\n",
       "      <td>The course is available via traditional and vi...</td>\n",
       "      <td>Red Hat introduces new OpenStack training cour...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aditi</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>598</td>\n",
       "      <td>ATRTAL0020200423eg4n000s8</td>\n",
       "      <td>Dragontail Systems Enters U.S. Market, Launche...</td>\n",
       "      <td>NEW YORK, April 23 -- Dragontail Systems Limit...</td>\n",
       "      <td>Dragontail Systems Limited (ASX: DTS), a softw...</td>\n",
       "      <td>Dragontail Systems Enters U.S. Market, Launche...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aditi</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>599</td>\n",
       "      <td>BWR0000020170710ed7a0009v</td>\n",
       "      <td>Protivix Hires Chad Ehmke and Launches Special...</td>\n",
       "      <td>\\nFRISCO, Texas--(BUSINESS WIRE)--July 10, 201...</td>\n",
       "      <td>Protivix's initial offerings will include solu...</td>\n",
       "      <td>Protivix Hires Chad Ehmke and Launches Special...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                         an  \\\n",
       "595         595  WATERTWN20141208eac30001o   \n",
       "596         596  TELWK00020130531e96500010   \n",
       "597         597  INTA000020140410ea4a00009   \n",
       "598         598  ATRTAL0020200423eg4n000s8   \n",
       "599         599  BWR0000020170710ed7a0009v   \n",
       "\n",
       "                                                 title  \\\n",
       "595  A REVIEW OF FOUR APPS THAT WILL HELP YOU SHOP ...   \n",
       "596  Transaction Network Services; TNS Unveils Uniq...   \n",
       "597   Red Hat introduces new OpenStack training course   \n",
       "598  Dragontail Systems Enters U.S. Market, Launche...   \n",
       "599  Protivix Hires Chad Ehmke and Launches Special...   \n",
       "\n",
       "                                               snippet  \\\n",
       "595  Want to save some cash while holiday shopping?...   \n",
       "596  2013 JUN 5 (VerticalNews) -- By a News Reporte...   \n",
       "597  Red Hat, Inc. (NYSE: RHT) said it has announce...   \n",
       "598  NEW YORK, April 23 -- Dragontail Systems Limit...   \n",
       "599  \\nFRISCO, Texas--(BUSINESS WIRE)--July 10, 201...   \n",
       "\n",
       "                                                  body  \\\n",
       "595  I found four apps to recommend after testing m...   \n",
       "596  TNS has partnered with leading mobile and land...   \n",
       "597  The course is available via traditional and vi...   \n",
       "598  Dragontail Systems Limited (ASX: DTS), a softw...   \n",
       "599  Protivix's initial offerings will include solu...   \n",
       "\n",
       "                                             full_text  \\\n",
       "595  A REVIEW OF FOUR APPS THAT WILL HELP YOU SHOP ...   \n",
       "596  Transaction Network Services; TNS Unveils Uniq...   \n",
       "597  Red Hat introduces new OpenStack training cour...   \n",
       "598  Dragontail Systems Enters U.S. Market, Launche...   \n",
       "599  Protivix Hires Chad Ehmke and Launches Special...   \n",
       "\n",
       "     Does it mention an innovation (yes,no,unsure)?  What is the company?  \\\n",
       "595                                             NaN                   NaN   \n",
       "596                                             NaN                   NaN   \n",
       "597                                             NaN                   NaN   \n",
       "598                                             NaN                   NaN   \n",
       "599                                             NaN                   NaN   \n",
       "\n",
       "     Where is company mentioned (title,body,snippet,all)?  \\\n",
       "595                                                NaN      \n",
       "596                                                NaN      \n",
       "597                                                NaN      \n",
       "598                                                NaN      \n",
       "599                                                NaN      \n",
       "\n",
       "     What is the product name?  \\\n",
       "595                        NaN   \n",
       "596                        NaN   \n",
       "597                        NaN   \n",
       "598                        NaN   \n",
       "599                        NaN   \n",
       "\n",
       "     Where is the product name mentioned(title,body,snippet,all)  \\\n",
       "595                                                NaN             \n",
       "596                                                NaN             \n",
       "597                                                NaN             \n",
       "598                                                NaN             \n",
       "599                                                NaN             \n",
       "\n",
       "     What could indicate that this is a product (for use in our algorithms, e.g. TM,R,C,CAPITAL LETTERS, Quotes,Used with certain key phrases or words etc.)?  \\\n",
       "595                                                NaN                                                                                                          \n",
       "596                                                NaN                                                                                                          \n",
       "597                                                NaN                                                                                                          \n",
       "598                                                NaN                                                                                                          \n",
       "599                                                NaN                                                                                                          \n",
       "\n",
       "     Features of the product, if mentioned assignee YN_INNOVATION  \n",
       "595                                    NaN    Aditi            no  \n",
       "596                                    NaN    Aditi           yes  \n",
       "597                                    NaN    Aditi            no  \n",
       "598                                    NaN    Aditi           yes  \n",
       "599                                    NaN    Diggy            no  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>an</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>body</th>\n",
       "      <th>full_text</th>\n",
       "      <th>Does it mention an innovation (yes,no,unsure)?</th>\n",
       "      <th>What is the company?</th>\n",
       "      <th>Where is company mentioned (title,body,snippet,all)?</th>\n",
       "      <th>What is the product name?</th>\n",
       "      <th>Where is the product name mentioned(title,body,snippet,all)</th>\n",
       "      <th>What could indicate that this is a product (for use in our algorithms, e.g. TM,R,C,CAPITAL LETTERS, Quotes,Used with certain key phrases or words etc.)?</th>\n",
       "      <th>Features of the product, if mentioned</th>\n",
       "      <th>assignee</th>\n",
       "      <th>YN_INNOVATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PNN0000020180426ee4p00006</td>\n",
       "      <td>Creaform and Metrologic Group Announce Worldwi...</td>\n",
       "      <td>Metrologic Group and Creaform have entered int...</td>\n",
       "      <td>Speed and volumetric accuracy\\n\\nThe CUBE-R™ e...</td>\n",
       "      <td>Creaform and Metrologic Group Announce Worldwi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>INVDAI0020150827eb8r00011</td>\n",
       "      <td>4 Growth Stocks Make Case For \"New Leader\" Status</td>\n",
       "      <td>The IPO Leaders screen can hold up to 16 stock...</td>\n",
       "      <td>Still, it makes sense to fill your watch list ...</td>\n",
       "      <td>4 Growth Stocks Make Case For \"New Leader\" Sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CNEWSN0020150403eb4200008</td>\n",
       "      <td>Microsoft puts kibosh on Kinect for Windows se...</td>\n",
       "      <td>Last year when Microsoft announced an adapter ...</td>\n",
       "      <td>Starting today, Microsoft will no longer be ma...</td>\n",
       "      <td>Microsoft puts kibosh on Kinect for Windows se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NDRSNH0020200312eg3a00003</td>\n",
       "      <td>County Council approves $850,000 for additiona...</td>\n",
       "      <td>ANDERSON — The Madison County Council approved...</td>\n",
       "      <td>The additional $16,637 will cover the expenses...</td>\n",
       "      <td>County Council approves $850,000 for additiona...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LBA0000020200124eg1o02o7x</td>\n",
       "      <td>Novartis, GBT sickle cell drugs too expensive,...</td>\n",
       "      <td>* U.S. group suggests SCD drugs too costly\\n\\n...</td>\n",
       "      <td>* Report may change after public comments\\n\\nB...</td>\n",
       "      <td>Novartis, GBT sickle cell drugs too expensive,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diggy</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         an  \\\n",
       "0           0  PNN0000020180426ee4p00006   \n",
       "1           1  INVDAI0020150827eb8r00011   \n",
       "2           2  CNEWSN0020150403eb4200008   \n",
       "3           3  NDRSNH0020200312eg3a00003   \n",
       "4           4  LBA0000020200124eg1o02o7x   \n",
       "\n",
       "                                               title  \\\n",
       "0  Creaform and Metrologic Group Announce Worldwi...   \n",
       "1  4 Growth Stocks Make Case For \"New Leader\" Status   \n",
       "2  Microsoft puts kibosh on Kinect for Windows se...   \n",
       "3  County Council approves $850,000 for additiona...   \n",
       "4  Novartis, GBT sickle cell drugs too expensive,...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  Metrologic Group and Creaform have entered int...   \n",
       "1  The IPO Leaders screen can hold up to 16 stock...   \n",
       "2  Last year when Microsoft announced an adapter ...   \n",
       "3  ANDERSON — The Madison County Council approved...   \n",
       "4  * U.S. group suggests SCD drugs too costly\\n\\n...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Speed and volumetric accuracy\\n\\nThe CUBE-R™ e...   \n",
       "1  Still, it makes sense to fill your watch list ...   \n",
       "2  Starting today, Microsoft will no longer be ma...   \n",
       "3  The additional $16,637 will cover the expenses...   \n",
       "4  * Report may change after public comments\\n\\nB...   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Creaform and Metrologic Group Announce Worldwi...   \n",
       "1  4 Growth Stocks Make Case For \"New Leader\" Sta...   \n",
       "2  Microsoft puts kibosh on Kinect for Windows se...   \n",
       "3  County Council approves $850,000 for additiona...   \n",
       "4  Novartis, GBT sickle cell drugs too expensive,...   \n",
       "\n",
       "   Does it mention an innovation (yes,no,unsure)?  What is the company?  \\\n",
       "0                                             NaN                   NaN   \n",
       "1                                             NaN                   NaN   \n",
       "2                                             NaN                   NaN   \n",
       "3                                             NaN                   NaN   \n",
       "4                                             NaN                   NaN   \n",
       "\n",
       "   Where is company mentioned (title,body,snippet,all)?  \\\n",
       "0                                                NaN      \n",
       "1                                                NaN      \n",
       "2                                                NaN      \n",
       "3                                                NaN      \n",
       "4                                                NaN      \n",
       "\n",
       "   What is the product name?  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "\n",
       "   Where is the product name mentioned(title,body,snippet,all)  \\\n",
       "0                                                NaN             \n",
       "1                                                NaN             \n",
       "2                                                NaN             \n",
       "3                                                NaN             \n",
       "4                                                NaN             \n",
       "\n",
       "   What could indicate that this is a product (for use in our algorithms, e.g. TM,R,C,CAPITAL LETTERS, Quotes,Used with certain key phrases or words etc.)?  \\\n",
       "0                                                NaN                                                                                                          \n",
       "1                                                NaN                                                                                                          \n",
       "2                                                NaN                                                                                                          \n",
       "3                                                NaN                                                                                                          \n",
       "4                                                NaN                                                                                                          \n",
       "\n",
       "   Features of the product, if mentioned assignee YN_INNOVATION  \n",
       "0                                    NaN    Diggy           yes  \n",
       "1                                    NaN    Diggy            no  \n",
       "2                                    NaN    Diggy            no  \n",
       "3                                    NaN    Diggy            no  \n",
       "4                                    NaN    Diggy            no  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8565fb7b9069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load pretrained model/tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoModelForTokenClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformers' is not defined"
     ]
    }
   ],
   "source": [
    "# Load pretrained model/tokenizer\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "model = transformers.AutoModelForTokenClassification.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'My', 'score': 0.6332293748855591, 'entity': 'LABEL_0', 'index': 1, 'start': 0, 'end': 2}, {'word': 'name', 'score': 0.5841968655586243, 'entity': 'LABEL_0', 'index': 2, 'start': 3, 'end': 7}, {'word': 'is', 'score': 0.6341058611869812, 'entity': 'LABEL_0', 'index': 3, 'start': 8, 'end': 10}, {'word': 'Slim', 'score': 0.6806789636611938, 'entity': 'LABEL_0', 'index': 4, 'start': 11, 'end': 15}, {'word': 'S', 'score': 0.5895118713378906, 'entity': 'LABEL_0', 'index': 5, 'start': 16, 'end': 17}, {'word': '##hady', 'score': 0.5776273608207703, 'entity': 'LABEL_0', 'index': 6, 'start': 17, 'end': 21}]\n"
     ]
    }
   ],
   "source": [
    "list_of_models = [\"bert-base-cased\"]\n",
    "\n",
    "for models in list_of_models:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(models)\n",
    "    model = transformers.AutoModelForTokenClassification.from_pretrained(models)\n",
    "    nlp = transformers.pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    example = \"My name is Slim Shady\"\n",
    "\n",
    "    ner_results = nlp(example)\n",
    "    print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/AM_BERT/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-04515c9e9e62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/AM_BERT/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/AM_BERT/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "tokenized = df[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 67)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 0.2242, -0.1600],\n",
       "         [-0.1264, -0.0502],\n",
       "         [ 0.0060, -0.0546],\n",
       "         ...,\n",
       "         [-0.2588,  0.0192],\n",
       "         [-0.0519, -0.0022],\n",
       "         [ 0.0271,  0.0509]],\n",
       "\n",
       "        [[ 0.3730, -0.1412],\n",
       "         [ 0.2883, -0.0452],\n",
       "         [-0.1132, -0.2743],\n",
       "         ...,\n",
       "         [ 0.0380, -0.1431],\n",
       "         [ 0.1389, -0.1838],\n",
       "         [ 0.2073, -0.1742]],\n",
       "\n",
       "        [[ 0.3688, -0.1723],\n",
       "         [ 0.2178, -0.1574],\n",
       "         [ 0.0812,  0.0288],\n",
       "         ...,\n",
       "         [ 0.1276,  0.0663],\n",
       "         [ 0.0656,  0.0177],\n",
       "         [ 0.0649, -0.0631]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4228, -0.1732],\n",
       "         [-0.0700, -0.2181],\n",
       "         [ 0.0136, -0.1202],\n",
       "         ...,\n",
       "         [ 0.2860, -0.0354],\n",
       "         [ 0.2490,  0.0076],\n",
       "         [ 0.3385, -0.0067]],\n",
       "\n",
       "        [[ 0.3429, -0.1162],\n",
       "         [ 0.0336, -0.0541],\n",
       "         [-0.0131,  0.0743],\n",
       "         ...,\n",
       "         [ 0.1254,  0.0637],\n",
       "         [ 0.1064,  0.0554],\n",
       "         [ 0.1715,  0.1375]],\n",
       "\n",
       "        [[ 0.2405, -0.2407],\n",
       "         [-0.0843, -0.2856],\n",
       "         [ 0.2792,  0.0059],\n",
       "         ...,\n",
       "         [ 0.1149, -0.0624],\n",
       "         [ 0.2247, -0.0467],\n",
       "         [ 0.3288,  0.1038]]]), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Slice the output for the first position for all the sequences, take all hidden unit outputs\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[1]\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6352601156069364"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-AM_BERT]",
   "language": "python",
   "name": "conda-env-.conda-AM_BERT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
